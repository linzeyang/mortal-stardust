"""
Enhanced AI Service for three-stage processing pipeline with multimodal analysis.
Provides psychological healing, practical solutions, and follow-up support.
"""

import time
from datetime import datetime
from typing import Any, Dict, List, Optional

import openai

from ..core.config import settings
from ..data.role_templates import UserRole, get_template_by_role
from ..services.media_service import media_processor
from ..utils.encryption import encrypt_data, encrypt_object


class EnhancedAIService:
    def __init__(self):
        # é…ç½®å¼‚æ­¥OpenAIå®¢æˆ·ç«¯ä»¥æ”¯æŒKimi API
        self.client = (
            openai.AsyncOpenAI(
                api_key=settings.OPENAI_API_KEY,
                base_url=settings.OPENAI_API_URL,
                timeout=30.0,  # å¢åŠ è¶…æ—¶æ—¶é—´
                max_retries=2   # è®¾ç½®é‡è¯•æ¬¡æ•°
            )
            if settings.OPENAI_API_KEY
            else None
        )
        self.model_name = settings.OPENAI_MODEL_NAME
        self.media_processor = media_processor

    async def process_experience_stage1(
        self, experience_data: Dict[str, Any], user_role: str
    ) -> Dict[str, Any]:
        """
        Stage 1: Psychological healing solution generation with multimodal analysis.

        Args:
            experience_data: User's experience data including form responses and media files
            user_role: User's role (workplace_newcomer, entrepreneur, student, other)

        Returns:
            Dict containing the psychological healing solution
        """
        try:
            # Get role template for personalized prompts
            role_template = get_template_by_role(UserRole(user_role))
            if not role_template:
                raise ValueError(f"Invalid user role: {user_role}")

            # Process multimodal inputs
            multimodal_analysis = await self._analyze_multimodal_inputs(
                experience_data.get("media_files", [])
            )

            # Build comprehensive context
            context = await self._build_stage1_context(
                experience_data, role_template, multimodal_analysis
            )

            # Generate psychological healing solution
            start_time = time.time()

            if self.client:
                solution = await self._generate_stage1_solution(context, role_template)
            else:
                solution = await self._mock_stage1_solution(context, role_template)

            processing_time = time.time() - start_time

            # Encrypt and structure response
            return await self._format_stage1_response(
                solution, processing_time, context
            )

        except Exception as e:
            raise Exception(f"Stage 1 AI processing failed: {str(e)}")

    async def _analyze_multimodal_inputs(
        self, media_files: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Analyze multimodal inputs (audio, image, video) for emotional context."""
        analysis = {
            "audio_insights": [],
            "visual_insights": [],
            "text_extractions": [],
            "emotional_indicators": [],
        }

        for media_file in media_files:
            try:
                media_type = media_file.get("mediaType", "").lower()

                if media_type == "audio":
                    audio_analysis = await self._analyze_audio_content(media_file)
                    analysis["audio_insights"].append(audio_analysis)

                elif media_type == "image":
                    image_analysis = await self._analyze_image_content(media_file)
                    analysis["visual_insights"].append(image_analysis)

                elif media_type == "video":
                    video_analysis = await self._analyze_video_content(media_file)
                    analysis["visual_insights"].append(video_analysis)

            except Exception as e:
                print(f"Failed to analyze media file {media_file.get('id')}: {e}")
                continue

        return analysis

    async def _analyze_audio_content(
        self, audio_file: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Analyze audio content for emotional tone and transcription."""
        # In a real implementation, this would use speech-to-text and emotion analysis
        return {
            "file_id": audio_file.get("id"),
            "transcription": "Audio content transcription would go here",
            "emotional_tone": "neutral",
            "speech_pace": "normal",
            "confidence": 0.7,
        }

    async def _analyze_image_content(
        self, image_file: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Analyze image content for visual context and emotional indicators."""
        # In a real implementation, this would use computer vision APIs
        return {
            "file_id": image_file.get("id"),
            "description": "Image content description would go here",
            "emotional_indicators": ["calm", "contemplative"],
            "objects_detected": [],
            "confidence": 0.6,
        }

    async def _analyze_video_content(
        self, video_file: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Analyze video content for both visual and audio information."""
        # In a real implementation, this would combine video and audio analysis
        return {
            "file_id": video_file.get("id"),
            "description": "Video content description would go here",
            "key_moments": [],
            "emotional_progression": "stable",
            "confidence": 0.65,
        }

    async def _build_stage1_context(
        self,
        experience_data: Dict[str, Any],
        role_template,
        multimodal_analysis: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Build comprehensive context for Stage 1 processing."""

        # Extract form data based on role template
        form_data = experience_data.get("data", {})

        # Build role-specific context
        role_context = {}
        for section in role_template.sections:
            section_data = {}
            for field in section.fields:
                field_value = form_data.get(field.id)
                if field_value is not None:
                    section_data[field.id] = field_value
            if section_data:
                role_context[section.id] = section_data

        # Determine stress/challenge level
        stress_indicators = self._extract_stress_indicators(form_data, role_template)

        # Build comprehensive context
        context = {
            "user_role": role_template.role,
            "template_name": role_template.name,
            "role_context": role_context,
            "stress_indicators": stress_indicators,
            "multimodal_insights": multimodal_analysis,
            "processing_timestamp": datetime.utcnow().isoformat(),
        }

        return context

    def _extract_stress_indicators(
        self, form_data: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Extract stress and emotional indicators from form data."""
        indicators = {
            "stress_level": 5,  # default
            "challenge_areas": [],
            "emotional_state": "neutral",
            "urgency_level": "moderate",
        }

        # Look for stress-related fields based on role
        if role_template.role == UserRole.WORKPLACE_NEWCOMER:
            indicators["stress_level"] = form_data.get("stress_level", 5)
            indicators["challenge_areas"] = form_data.get("challenge_category", [])

        elif role_template.role == UserRole.ENTREPRENEUR:
            indicators["stress_level"] = form_data.get("urgency_level", 5)
            indicators["challenge_areas"] = form_data.get("challenge_areas", [])

        elif role_template.role == UserRole.STUDENT:
            indicators["stress_level"] = form_data.get("stress_intensity", 5)
            indicators["challenge_areas"] = form_data.get("problem_categories", [])

        return indicators

    def _extract_form_data(self, experience_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract form data from experience data."""
        return experience_data.get("data", {})

    async def _generate_stage1_solution(
        self, context: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Generate Stage 1 psychological healing solution using OpenAI."""

        # Use role template's stage 1 prompt
        base_prompt = role_template.aiPrompts.stage1_prompt

        # Fill in context variables
        prompt_variables = {}
        for var in role_template.aiPrompts.context_variables:
            value = self._extract_context_value(context, var)
            prompt_variables[var] = value

        # Format the prompt with actual data
        try:
            formatted_prompt = base_prompt.format(**prompt_variables)
        except KeyError:
            # Handle missing variables gracefully
            formatted_prompt = base_prompt

        # Add multimodal insights to prompt
        if context["multimodal_insights"]["audio_insights"]:
            formatted_prompt += "\n\nè¯­éŸ³åˆ†ææ˜¾ç¤ºï¼š"
            for insight in context["multimodal_insights"]["audio_insights"]:
                formatted_prompt += (
                    f"\n- è¯­éŸ³æƒ…ç»ª: {insight.get('emotional_tone', 'neutral')}"
                )

        if context["multimodal_insights"]["visual_insights"]:
            formatted_prompt += "\n\nè§†è§‰å†…å®¹åˆ†æï¼š"
            for insight in context["multimodal_insights"]["visual_insights"]:
                formatted_prompt += (
                    f"\n- è§†è§‰æƒ…ç»ªæŒ‡æ ‡: {insight.get('emotional_indicators', [])}"
                )

        # Make API call to Kimi
        try:
            print(f"ğŸ¤– è°ƒç”¨Kimi API - æ¨¡å‹: {self.model_name}")
            print(f"ğŸ¤– APIç«¯ç‚¹: {self.client.base_url}")
            
            response = await self.client.chat.completions.create(
                model=self.model_name,  # ä½¿ç”¨é…ç½®çš„Kimiæ¨¡å‹
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å¿ƒç†å¥åº·ä¸“å®¶ï¼Œä¸“é—¨æä¾›æ¸©æš–ã€ä¸“ä¸šçš„å¿ƒç†ç–—æ„ˆæ”¯æŒã€‚ä½ çš„å›åº”åº”è¯¥ä½“ç°æ·±åº¦ç†è§£ã€å…±æƒ…å’Œå®ç”¨çš„å¿ƒç†å¥åº·æŒ‡å¯¼ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­è¨€è¦æ¸©å’Œã€æœ‰åŒç†å¿ƒï¼Œæä¾›å…·ä½“å¯è¡Œçš„å»ºè®®ã€‚",
                    },
                    {"role": "user", "content": formatted_prompt},
                ],
                temperature=0.7,
                max_tokens=3000,  # Kimiæ”¯æŒæ›´é•¿çš„è¾“å‡º
                stream=False
            )
            print(f"âœ… Kimi APIè°ƒç”¨æˆåŠŸ")
            
        except Exception as api_error:
            print(f"âŒ Kimi APIè°ƒç”¨å¤±è´¥: {type(api_error).__name__}: {str(api_error)}")
            raise Exception(f"Kimi APIè°ƒç”¨å¤±è´¥: {str(api_error)}")

        content = response.choices[0].message.content

        # Parse and structure the response
        return {
            "title": "å¿ƒç†ç–—æ„ˆä¸æƒ…æ„Ÿæ”¯æŒæ–¹æ¡ˆ",
            "content": content,
            "recommendations": self._extract_recommendations(content),
            "coping_strategies": self._extract_coping_strategies(content),
            "emotional_support": self._extract_emotional_support(content),
            "resources": self._get_stage1_resources(context),
            "confidence_score": 0.85,
            "prompt_used": formatted_prompt,
            "model_params": {
                "model": self.model_name,
                "temperature": 0.7,
                "max_tokens": 2000,
            },
        }

    async def _mock_stage1_solution(
        self, context: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Generate mock Stage 1 solution for testing purposes."""

        role_name = role_template.name
        stress_level = context["stress_indicators"]["stress_level"]
        challenge_areas = context["stress_indicators"]["challenge_areas"]

        mock_content = f"""
        äº²çˆ±çš„{role_name}æœ‹å‹ï¼Œ

        æˆ‘ç†è§£æ‚¨å½“å‰é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå‹åŠ›ç­‰çº§ä¸º{stress_level}/10ï¼Œä¸»è¦å›°éš¾é›†ä¸­åœ¨{", ".join(challenge_areas[:3]) if challenge_areas else "ä¸ªäººæˆé•¿"}ç­‰æ–¹é¢ã€‚

        ## æƒ…æ„Ÿè®¤çŸ¥ä¸ç†è§£
        æ‚¨çš„æ„Ÿå—æ˜¯å®Œå…¨æ­£å¸¸å’Œå¯ç†è§£çš„ã€‚é¢å¯¹è¿™äº›æŒ‘æˆ˜æ—¶äº§ç”Ÿçš„ç„¦è™‘ã€å›°æƒ‘æˆ–å‹åŠ›éƒ½æ˜¯äººä¹‹å¸¸æƒ…ã€‚

        ## å¿ƒç†ç–—æ„ˆå»ºè®®
        1. **æ¥çº³å½“å‰çŠ¶æ€**ï¼šé¦–å…ˆè¦æ¥å—å¹¶è®¤å¯è‡ªå·±çš„æ„Ÿå—ï¼Œä¸è¦è¿‡åº¦è‡ªè´£
        2. **æƒ…ç»ªè°ƒèŠ‚æŠ€å·§**ï¼šä½¿ç”¨æ·±å‘¼å¸ã€æ­£å¿µå†¥æƒ³ç­‰æ–¹æ³•ç®¡ç†ç„¦è™‘æƒ…ç»ª
        3. **ç§¯æè®¤çŸ¥é‡æ„**ï¼šå°è¯•ä»ä¸åŒè§’åº¦çœ‹å¾…å½“å‰çš„å›°éš¾
        4. **è‡ªæˆ‘å…³æ€€å®è·µ**ï¼šç»™äºˆè‡ªå·±è¶³å¤Ÿçš„ç†è§£å’Œæ”¯æŒ

        ## å³æ—¶ç¼“è§£ç­–ç•¥
        - æ¯æ—¥10åˆ†é’Ÿæ­£å¿µç»ƒä¹ 
        - å†™æƒ…ç»ªæ—¥è®°ï¼Œè®°å½•æ„Ÿå—å˜åŒ–
        - ä¸ä¿¡ä»»çš„æœ‹å‹æˆ–å®¶äººåˆ†äº«æ„Ÿå—
        - é€‚é‡è¿åŠ¨å’Œå……è¶³ç¡çœ 

        è¯·è®°ä½ï¼Œæ‚¨å¹¶ä¸å­¤å•ï¼Œè¿™ä¸ªè¿‡ç¨‹éœ€è¦æ—¶é—´ï¼Œè¯·å¯¹è‡ªå·±ä¿æŒè€å¿ƒå’Œå–„æ„ã€‚
        """

        return {
            "title": "å¿ƒç†ç–—æ„ˆä¸æƒ…æ„Ÿæ”¯æŒæ–¹æ¡ˆ",
            "content": mock_content.strip(),
            "recommendations": [
                "æ¥çº³å½“å‰çš„æƒ…æ„ŸçŠ¶æ€",
                "ç»ƒä¹ æ·±å‘¼å¸å’Œæ­£å¿µæŠ€å·§",
                "å»ºç«‹å¥åº·çš„åº”å¯¹æœºåˆ¶",
                "å¯»æ±‚é€‚å½“çš„ç¤¾ä¼šæ”¯æŒ",
            ],
            "coping_strategies": [
                "æ·±å‘¼å¸ç»ƒä¹ ï¼ˆ4-7-8æŠ€å·§ï¼‰",
                "æ­£å¿µå†¥æƒ³ï¼ˆæ¯æ—¥10åˆ†é’Ÿï¼‰",
                "æƒ…ç»ªæ—¥è®°è®°å½•",
                "é€‚é‡è¿åŠ¨å’Œæ”¾æ¾",
            ],
            "emotional_support": [
                "ç†è§£å’Œæ¥çº³è‡ªå·±çš„æ„Ÿå—",
                "è®¤è¯†åˆ°å›°éš¾æ˜¯æš‚æ—¶çš„",
                "ç›¸ä¿¡è‡ªå·±æœ‰èƒ½åŠ›å…‹æœæŒ‘æˆ˜",
                "å»ºç«‹ç§¯æçš„è‡ªæˆ‘å¯¹è¯",
            ],
            "resources": self._get_stage1_resources(context),
            "confidence_score": 0.75,
            "prompt_used": "æ¨¡æ‹Ÿæç¤ºå†…å®¹",
            "model_params": {
                "model": "mock-gpt-4",
                "temperature": 0.7,
                "max_tokens": 2000,
            },
        }

    def _extract_context_value(
        self, context: Dict[str, Any], variable_name: str
    ) -> str:
        """Extract context value for prompt variable."""
        role_context = context.get("role_context", {})

        # Search through all sections for the variable
        for section_id, section_data in role_context.items():
            if variable_name in section_data:
                value = section_data[variable_name]
                if isinstance(value, list):
                    return ", ".join(str(v) for v in value)
                return str(value)

        # Fallback to default values
        defaults = {
            "stress_level": str(context["stress_indicators"]["stress_level"]),
            "stress_intensity": str(context["stress_indicators"]["stress_level"]),
            "urgency_level": str(context["stress_indicators"]["stress_level"]),
            "challenge_category": ", ".join(
                context["stress_indicators"]["challenge_areas"]
            ),
            "challenge_areas": ", ".join(
                context["stress_indicators"]["challenge_areas"]
            ),
            "problem_categories": ", ".join(
                context["stress_indicators"]["challenge_areas"]
            ),
        }

        return defaults.get(variable_name, "æœªæä¾›")

    def _extract_recommendations(self, content: str) -> List[str]:
        """Extract recommendations from AI response."""
        # Simple extraction logic - in production, this could be more sophisticated
        recommendations = []
        lines = content.split("\n")

        for line in lines:
            line = line.strip()
            if line.startswith(("1.", "2.", "3.", "4.", "5.", "-", "â€¢")):
                # Clean up the line
                clean_line = line.lstrip("123456789.-â€¢ ").strip()
                if len(clean_line) > 10:  # Filter out very short lines
                    recommendations.append(clean_line)

        # Fallback recommendations if extraction fails
        if not recommendations:
            recommendations = [
                "æ¥çº³å½“å‰çš„æƒ…æ„ŸçŠ¶æ€ï¼Œä¸è¦è¿‡åº¦è‡ªè´£",
                "ç»ƒä¹ æ·±å‘¼å¸å’Œæ­£å¿µå†¥æƒ³æŠ€å·§",
                "å¯»æ±‚åˆé€‚çš„ç¤¾ä¼šæ”¯æŒå’Œä¸“ä¸šå¸®åŠ©",
                "å»ºç«‹å¥åº·çš„ç”Ÿæ´»ä¹ æƒ¯å’Œåº”å¯¹æœºåˆ¶",
            ]

        return recommendations[:6]  # Limit to 6 recommendations

    def _extract_coping_strategies(self, content: str) -> List[str]:
        """Extract coping strategies from AI response."""
        strategies = [
            "æ·±å‘¼å¸ç»ƒä¹ ï¼ˆ4-7-8å‘¼å¸æ³•ï¼‰",
            "æ­£å¿µå†¥æƒ³ï¼ˆæ¯æ—¥10-15åˆ†é’Ÿï¼‰",
            "æ¸è¿›æ€§è‚Œè‚‰æ”¾æ¾è®­ç»ƒ",
            "å†™æƒ…ç»ªæ—¥è®°è®°å½•æ„Ÿå—å˜åŒ–",
            "é€‚é‡æœ‰æ°§è¿åŠ¨ï¼ˆå¦‚æ•£æ­¥ã€æ…¢è·‘ï¼‰",
            "ä¸ä¿¡ä»»çš„äººåˆ†äº«å’Œå€¾è¯‰",
        ]
        return strategies

    def _extract_emotional_support(self, content: str) -> List[str]:
        """Extract emotional support elements from AI response."""
        support_elements = [
            "æ‚¨çš„æ„Ÿå—æ˜¯å®Œå…¨æ­£å¸¸å’Œå¯ç†è§£çš„",
            "æ¯ä¸ªäººéƒ½ä¼šé‡åˆ°å›°éš¾ï¼Œæ‚¨å¹¶ä¸å­¤å•",
            "è¿™ä¸ªè¿‡ç¨‹éœ€è¦æ—¶é—´ï¼Œè¯·å¯¹è‡ªå·±ä¿æŒè€å¿ƒ",
            "æ‚¨å·²ç»å±•ç°å‡ºäº†é¢å¯¹å›°éš¾çš„å‹‡æ°”",
            "ç›¸ä¿¡è‡ªå·±æœ‰èƒ½åŠ›é€æ­¥å…‹æœå½“å‰çš„æŒ‘æˆ˜",
            "å¯»æ±‚å¸®åŠ©æ˜¯æ˜æ™ºå’Œå‹‡æ•¢çš„é€‰æ‹©",
        ]
        return support_elements

    def _get_stage1_resources(self, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Get recommended resources for Stage 1."""
        resources = [
            {
                "type": "article",
                "title": "æƒ…ç»ªè°ƒèŠ‚æŠ€å·§æŒ‡å—",
                "description": "å­¦ä¹ æœ‰æ•ˆçš„æƒ…ç»ªç®¡ç†å’Œå‹åŠ›ç¼“è§£æ–¹æ³•",
                "url": "#",
                "category": "å¿ƒç†å¥åº·",
            },
            {
                "type": "app",
                "title": "æ­£å¿µå†¥æƒ³åº”ç”¨",
                "description": "å¼•å¯¼å¼å†¥æƒ³å’Œæ”¾æ¾ç»ƒä¹ ",
                "url": "#",
                "category": "å¿ƒç†å¥åº·",
            },
            {
                "type": "professional",
                "title": "å¿ƒç†å’¨è¯¢æœåŠ¡",
                "description": "ä¸“ä¸šå¿ƒç†å¥åº·æ”¯æŒå’Œå’¨è¯¢",
                "url": "#",
                "category": "ä¸“ä¸šæ”¯æŒ",
            },
            {
                "type": "book",
                "title": "ã€Šæƒ…ç»ªæ€¥æ•‘ã€‹",
                "description": "Guy Winchè‘—ï¼Œå®ç”¨çš„å¿ƒç†è‡ªåŠ©æŒ‡å—",
                "url": "#",
                "category": "æ¨èé˜…è¯»",
            },
        ]

        # Add role-specific resources
        user_role = context.get("user_role")
        if user_role == UserRole.WORKPLACE_NEWCOMER:
            resources.append(
                {
                    "type": "article",
                    "title": "èŒåœºå‹åŠ›ç®¡ç†",
                    "description": "æ–°å‘˜å·¥é€‚åº”èŒåœºçš„å¿ƒç†è°ƒé€‚ç­–ç•¥",
                    "url": "#",
                    "category": "èŒåœºå¿ƒç†",
                }
            )
        elif user_role == UserRole.ENTREPRENEUR:
            resources.append(
                {
                    "type": "podcast",
                    "title": "åˆ›ä¸šè€…å¿ƒç†å¥åº·",
                    "description": "åˆ›ä¸šå‹åŠ›ä¸‹çš„å¿ƒç†ä¿å¥å’Œå¹³è¡¡",
                    "url": "#",
                    "category": "åˆ›ä¸šå¿ƒç†",
                }
            )
        elif user_role == UserRole.STUDENT:
            resources.append(
                {
                    "type": "article",
                    "title": "å­¦ç”Ÿå¿ƒç†å¥åº·æŒ‡å—",
                    "description": "å­¦ä¸šå‹åŠ›å’Œç”Ÿæ´»å¹³è¡¡çš„å¿ƒç†æ”¯æŒ",
                    "url": "#",
                    "category": "å­¦ç”Ÿå¿ƒç†",
                }
            )

        return resources

    async def _format_stage1_response(
        self, solution: Dict[str, Any], processing_time: float, context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Format and encrypt Stage 1 response."""

        # Encrypt sensitive content
        encrypted_content = {
            "title": encrypt_data(solution["title"]),
            "content": encrypt_data(solution["content"]),
            "recommendations": [
                encrypt_data(rec) for rec in solution["recommendations"]
            ],
            "coping_strategies": [
                encrypt_data(strategy) for strategy in solution["coping_strategies"]
            ],
            "emotional_support": [
                encrypt_data(support) for support in solution["emotional_support"]
            ],
            "resources": solution["resources"],  # Resources can remain unencrypted
        }

        # Metadata
        metadata = {
            "stage": 1,
            "stage_name": "psychological_healing",
            "user_role": context["user_role"],
            "processing_time": processing_time,
            "confidence_score": solution["confidence_score"],
            "model_params": encrypt_object(solution["model_params"]),
            "multimodal_analysis": encrypt_object(context["multimodal_insights"]),
            "generated_at": datetime.utcnow().isoformat(),
            "version": "1.0",
        }

        return {
            "content": encrypted_content,
            "metadata": metadata,
            "stage": 1,
            "success": True,
        }

    async def process_experience_stage2(
        self,
        experience_data: Dict[str, Any],
        stage1_solution: Optional[Dict[str, Any]] = None,
        user_role: str = "other",
        additional_context: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """
        Process Stage 2: Practical Solution Generation

        Takes the psychological foundation from Stage 1 and generates
        practical, actionable solutions and strategies.
        """
        start_time = datetime.utcnow()

        try:
            print(f"ğŸ”„ Stage 2å¤„ç†å¼€å§‹ï¼Œç”¨æˆ·è§’è‰²: {user_role}")
            print(f"ğŸ“Š Experienceæ•°æ®: {experience_data.get('_id', 'No ID')}")
            print(f"ğŸ”— Stage1è§£å†³æ–¹æ¡ˆ: {'å­˜åœ¨' if stage1_solution else 'ä¸å­˜åœ¨'}")
            
            # Get user role template
            role_template = get_template_by_role(UserRole(user_role))
            print(f"âœ… è·å–è§’è‰²æ¨¡æ¿æˆåŠŸ: {role_template.name if role_template else 'None'}")

            # Build context for Stage 2 processing
            context = await self._build_stage2_context(
                experience_data,
                stage1_solution,
                role_template,
                additional_context or {},
            )

            # Generate Stage 2 practical solution
            print(f"ğŸ¤– AIå®¢æˆ·ç«¯çŠ¶æ€: {'å¯ç”¨' if self.client else 'ä¸å¯ç”¨'}")
            if self.client:  # Use real AI if available
                print(f"ğŸ”„ è°ƒç”¨çœŸå®AIæœåŠ¡...")
                solution = await self._generate_stage2_solution(context, role_template)
                print(f"âœ… AIæœåŠ¡è°ƒç”¨å®Œæˆ")
            else:
                print(f"ğŸ”„ ä½¿ç”¨æ¨¡æ‹ŸAIæœåŠ¡...")
                solution = await self._mock_stage2_solution(context, role_template)
                print(f"âœ… æ¨¡æ‹ŸAIæœåŠ¡å®Œæˆ")

            # Calculate processing time
            processing_time = (datetime.utcnow() - start_time).total_seconds()

            # Encrypt sensitive content
            encrypted_content = {
                "title": encrypt_data(solution["title"]),
                "description": encrypt_data(solution["description"]),
                "actionSteps": [encrypt_data(step) for step in solution["actionSteps"]],
                "recommendations": [
                    encrypt_data(rec) for rec in solution["recommendations"]
                ],
                "implementation_timeline": solution["implementation_timeline"],
                "resources": solution["resources"],
                "success_metrics": solution["success_metrics"],
            }

            # AI processing metadata
            ai_metadata = {
                "stage": 2,
                "stage_name": "practical_solutions",
                "user_role": context["user_role"],
                "processing_time": processing_time,
                "confidence_score": solution["confidence_score"],
                "model_params": encrypt_object(solution.get("model_params", {})),
                "stage1_integration": bool(stage1_solution),
                "multimodal_analysis": encrypt_object(context["multimodal_insights"]),
                "generated_at": datetime.utcnow().isoformat(),
                "version": "1.0",
            }

            return {
                "content": encrypted_content,
                "ai_metadata": ai_metadata,
                "confidence_score": solution["confidence_score"],
                "stage": 2,
                "success": True,
            }

        except Exception as e:
            print(f"âŒ Stage 2 processing error: {type(e).__name__}: {e}")
            import traceback
            print(f"ğŸ“‹ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise Exception(f"Stage 2 processing failed: {str(e)}")

    async def _build_stage2_context(
        self,
        experience_data: Dict[str, Any],
        stage1_solution: Optional[Dict[str, Any]],
        role_template,
        additional_context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Build comprehensive context for Stage 2 processing."""

        # Extract form data
        form_data = self._extract_form_data(experience_data)

        # Analyze multimodal content
        multimodal_analysis = await self._analyze_multimodal_inputs(
            experience_data.get("media_files", [])
        )

        # Extract practical challenge indicators
        practical_indicators = self._extract_practical_indicators(
            form_data, role_template
        )

        # Build context for practical solutions
        context = {
            "user_role": role_template.role.value,
            "template_name": role_template.name,
            "form_data": form_data,
            "practical_indicators": practical_indicators,
            "multimodal_insights": multimodal_analysis,
            "stage1_foundation": (
                self._extract_stage1_foundation(stage1_solution)
                if stage1_solution
                else None
            ),
            "additional_context": additional_context,
            "processing_timestamp": datetime.utcnow().isoformat(),
        }

        return context

    def _extract_practical_indicators(
        self, form_data: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Extract practical challenge indicators from form data."""
        indicators = {
            "complexity_level": 5,  # default
            "implementation_areas": [],
            "resource_needs": [],
            "time_constraints": "moderate",
            "priority_level": "medium",
        }

        # Extract based on role template
        if role_template.role == UserRole.WORKPLACE_NEWCOMER:
            indicators["complexity_level"] = form_data.get("task_complexity", 5)
            indicators["implementation_areas"] = form_data.get("skill_gaps", [])
            indicators["resource_needs"] = form_data.get("support_needed", [])

        elif role_template.role == UserRole.ENTREPRENEUR:
            indicators["complexity_level"] = form_data.get("business_complexity", 5)
            indicators["implementation_areas"] = form_data.get("business_areas", [])
            indicators["resource_needs"] = form_data.get("resource_constraints", [])

        elif role_template.role == UserRole.STUDENT:
            indicators["complexity_level"] = form_data.get("problem_difficulty", 5)
            indicators["implementation_areas"] = form_data.get("study_areas", [])
            indicators["resource_needs"] = form_data.get("learning_support", [])

        return indicators

    def _extract_stage1_foundation(
        self, stage1_solution: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Extract useful foundation from Stage 1 solution."""
        if not stage1_solution:
            return {}

        content = stage1_solution.get("content", {})

        return {
            "emotional_state": "stabilized",  # Assume Stage 1 helped
            "coping_mechanisms": content.get("coping_strategies", []),
            "psychological_readiness": True,
            "support_system": content.get("emotional_support", []),
            "confidence_level": stage1_solution.get("metadata", {}).get(
                "confidence_score", 0.7
            ),
        }

    async def _generate_stage2_solution(
        self, context: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Generate Stage 2 practical solution using OpenAI."""

        # Build comprehensive prompt for practical solutions
        base_prompt = (
            role_template.aiPrompts.stage2_prompt
            if hasattr(role_template.aiPrompts, "stage2_prompt")
            else self._get_default_stage2_prompt(role_template)
        )

        # Fill in context variables
        prompt_variables = {
            "user_role": context["user_role"],
            "complexity_level": context["practical_indicators"]["complexity_level"],
            "implementation_areas": ", ".join(
                context["practical_indicators"]["implementation_areas"][:3]
            ),
            "resource_needs": ", ".join(
                context["practical_indicators"]["resource_needs"][:3]
            ),
            "stage1_foundation": (
                "å·²å»ºç«‹æƒ…æ„ŸåŸºç¡€" if context["stage1_foundation"] else "éœ€è¦å¹¶è¡Œæƒ…æ„Ÿæ”¯æŒ"
            ),
        }

        # Format the prompt
        try:
            formatted_prompt = base_prompt.format(**prompt_variables)
        except KeyError:
            formatted_prompt = base_prompt

        # Add multimodal insights
        if context["multimodal_insights"]["audio_insights"]:
            formatted_prompt += "\n\nè¯­éŸ³åˆ†ææ˜¾ç¤ºçš„å®é™…éœ€æ±‚ï¼š"
            for insight in context["multimodal_insights"]["audio_insights"]:
                formatted_prompt += (
                    f"\n- è¡¨è¾¾æ–¹å¼: {insight.get('speaking_pattern', 'normal')}"
                )

        # Make API call
        response = await self.client.chat.completions.create(
            model=self.model_name,  # ä½¿ç”¨é…ç½®çš„Kimiæ¨¡å‹
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å®ç”¨è§£å†³æ–¹æ¡ˆä¸“å®¶ï¼Œä¸“é—¨æä¾›å…·ä½“ã€å¯æ‰§è¡Œçš„è¡ŒåŠ¨è®¡åˆ’å’Œç­–ç•¥ã€‚ä½ çš„å»ºè®®åº”è¯¥å…·ä½“ã€å¯æ“ä½œã€å¾ªåºæ¸è¿›ã€‚",
                },
                {"role": "user", "content": formatted_prompt},
            ],
            temperature=0.6,
            max_tokens=2500,
        )

        content = response.choices[0].message.content

        # Parse and structure the response
        return {
            "title": "å®ç”¨è§£å†³æ–¹æ¡ˆä¸è¡ŒåŠ¨è®¡åˆ’",
            "description": content,
            "actionSteps": self._extract_action_steps(content),
            "recommendations": self._extract_practical_recommendations(content),
            "implementation_timeline": self._generate_timeline(context),
            "resources": self._get_stage2_resources(context),
            "success_metrics": self._define_success_metrics(context),
            "confidence_score": 0.82,
            "model_params": {
                "model": self.model_name,
                "temperature": 0.6,
                "max_tokens": 2500,
            },
        }

    async def _mock_stage2_solution(
        self, context: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Generate mock Stage 2 solution for testing purposes."""

        role_name = role_template.name
        complexity = context["practical_indicators"]["complexity_level"]
        areas = context["practical_indicators"]["implementation_areas"]

        mock_description = f"""
        åŸºäºæ‚¨ä½œä¸º{role_name}çš„å…·ä½“æƒ…å†µï¼Œä»¥ä¸‹æ˜¯é’ˆå¯¹å¤æ‚åº¦{complexity}/10çš„å®ç”¨è§£å†³æ–¹æ¡ˆï¼š

        ## æ ¸å¿ƒç­–ç•¥
        é’ˆå¯¹æ‚¨åœ¨{", ".join(areas[:3]) if areas else "å„ä¸ªæ–¹é¢"}é‡åˆ°çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬åˆ¶å®šäº†ä»¥ä¸‹å¾ªåºæ¸è¿›çš„è§£å†³æ–¹æ¡ˆã€‚

        ## å®æ–½è®¡åˆ’
        1. **çŸ­æœŸç›®æ ‡**ï¼ˆ1-2å‘¨ï¼‰ï¼šå»ºç«‹åŸºç¡€æ¡†æ¶å’Œåˆæ­¥è¡ŒåŠ¨
        2. **ä¸­æœŸç›®æ ‡**ï¼ˆ1-2ä¸ªæœˆï¼‰ï¼šæ·±åŒ–å®æ–½å’Œè°ƒæ•´ä¼˜åŒ–
        3. **é•¿æœŸç›®æ ‡**ï¼ˆ3-6ä¸ªæœˆï¼‰ï¼šå·©å›ºæˆæœå’ŒæŒç»­æ”¹è¿›

        ## å…·ä½“è¡ŒåŠ¨æ­¥éª¤
        æ¯ä¸ªæ­¥éª¤éƒ½é…æœ‰æ˜ç¡®çš„æ‰§è¡Œæ ‡å‡†å’ŒæˆåŠŸæŒ‡æ ‡ï¼Œç¡®ä¿æ‚¨èƒ½å¤Ÿæœ‰åºæ¨è¿›ã€‚

        ## èµ„æºæ•´åˆ
        æˆ‘ä»¬å·²ä¸ºæ‚¨å‡†å¤‡äº†ç›¸å…³çš„å·¥å…·ã€æ–¹æ³•å’Œæ”¯æŒèµ„æºï¼ŒåŠ©æ‚¨é¡ºåˆ©å®æ–½ã€‚
        """

        return {
            "title": "å®ç”¨è§£å†³æ–¹æ¡ˆä¸è¡ŒåŠ¨è®¡åˆ’",
            "description": mock_description.strip(),
            "actionSteps": [
                "ç¬¬ä¸€æ­¥ï¼šæƒ…å†µåˆ†æå’Œç›®æ ‡è®¾å®š",
                "ç¬¬äºŒæ­¥ï¼šåˆ¶å®šè¯¦ç»†çš„å®æ–½è®¡åˆ’",
                "ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹æ‰§è¡Œå¹¶è®°å½•è¿›å±•",
                "ç¬¬å››æ­¥ï¼šå®šæœŸè¯„ä¼°å’Œè°ƒæ•´ç­–ç•¥",
                "ç¬¬äº”æ­¥ï¼šå·©å›ºæˆæœå’ŒæŒç»­ä¼˜åŒ–",
            ],
            "recommendations": [
                "é‡‡ç”¨æ¸è¿›å¼å®æ–½æ–¹æ³•",
                "å»ºç«‹å®šæœŸå›é¡¾æœºåˆ¶",
                "ä¿æŒçµæ´»æ€§å’Œé€‚åº”æ€§",
                "å¯»æ±‚å¿…è¦çš„å¤–éƒ¨æ”¯æŒ",
            ],
            "implementation_timeline": {
                "phase1": "1-2å‘¨ï¼šåŸºç¡€å»ºç«‹",
                "phase2": "3-8å‘¨ï¼šæ·±å…¥å®æ–½",
                "phase3": "9-24å‘¨ï¼šä¼˜åŒ–å®Œå–„",
            },
            "resources": self._get_stage2_resources(context),
            "success_metrics": [
                "æ¯å‘¨å®Œæˆè®¾å®šçš„è¡ŒåŠ¨æ­¥éª¤",
                "é—®é¢˜è§£å†³ç¨‹åº¦æå‡50%ä»¥ä¸Š",
                "ä¸ªäººæ»¡æ„åº¦è¾¾åˆ°7/10ä»¥ä¸Š",
                "å»ºç«‹å¯æŒç»­çš„æ”¹è¿›æœºåˆ¶",
            ],
            "confidence_score": 0.78,
        }

    def _get_default_stage2_prompt(self, role_template) -> str:
        """Get default Stage 2 prompt if template doesn't have one."""
        return f"""
        ä½œä¸º{role_template.name}ï¼Œç”¨æˆ·é¢ä¸´å¤æ‚åº¦ä¸º{{complexity_level}}/10çš„æŒ‘æˆ˜ï¼Œä¸»è¦æ¶‰åŠ{{implementation_areas}}ç­‰é¢†åŸŸã€‚
        ç”¨æˆ·éœ€è¦{{resource_needs}}æ–¹é¢çš„æ”¯æŒã€‚{{stage1_foundation}}

        è¯·æä¾›ï¼š
        1. å…·ä½“çš„è¡ŒåŠ¨æ­¥éª¤ï¼ˆ5-7ä¸ªæ­¥éª¤ï¼‰
        2. å®ç”¨çš„å»ºè®®å’Œç­–ç•¥
        3. å®æ–½æ—¶é—´å®‰æ’
        4. æˆåŠŸè¯„ä¼°æ ‡å‡†
        5. æ‰€éœ€èµ„æºå’Œå·¥å…·

        è¦æ±‚ï¼šæ–¹æ¡ˆè¦å…·ä½“å¯æ‰§è¡Œï¼Œå¾ªåºæ¸è¿›ï¼Œè€ƒè™‘ç”¨æˆ·çš„å®é™…æƒ…å†µå’Œèƒ½åŠ›ã€‚
        """

    def _extract_action_steps(self, content: str) -> List[str]:
        """Extract action steps from AI response."""
        # Simple extraction logic - in production, use more sophisticated parsing
        steps = []
        lines = content.split("\n")
        for line in lines:
            if any(
                keyword in line.lower() for keyword in ["æ­¥éª¤", "ç¬¬", "è¡ŒåŠ¨", "æ‰§è¡Œ"]
            ):
                if len(line.strip()) > 10:  # Filter out short lines
                    steps.append(line.strip())

        if not steps:  # Fallback
            steps = [
                "åˆ†æç°çŠ¶å’Œè®¾å®šç›®æ ‡",
                "åˆ¶å®šè¯¦ç»†å®æ–½è®¡åˆ’",
                "å¼€å§‹æ‰§è¡Œæ ¸å¿ƒè¡ŒåŠ¨",
                "ç›‘æ§è¿›å±•å’Œè°ƒæ•´",
                "è¯„ä¼°ç»“æœå’Œä¼˜åŒ–",
            ]

        return steps[:7]  # Limit to 7 steps

    def _extract_practical_recommendations(self, content: str) -> List[str]:
        """Extract practical recommendations from AI response."""
        recommendations = []
        lines = content.split("\n")
        for line in lines:
            if any(
                keyword in line.lower() for keyword in ["å»ºè®®", "æ¨è", "æ–¹æ³•", "ç­–ç•¥"]
            ):
                if len(line.strip()) > 15:
                    recommendations.append(line.strip())

        if not recommendations:
            recommendations = [
                "åˆ¶å®šæ˜ç¡®çš„æ—¶é—´è®¡åˆ’",
                "å¯»æ±‚ä¸“ä¸šæŒ‡å¯¼å’Œæ”¯æŒ",
                "å»ºç«‹è¿›åº¦è·Ÿè¸ªæœºåˆ¶",
                "ä¿æŒç§¯æçš„å­¦ä¹ æ€åº¦",
            ]

        return recommendations[:6]

    def _generate_timeline(self, context: Dict[str, Any]) -> Dict[str, str]:
        """Generate implementation timeline based on context."""
        complexity = context["practical_indicators"]["complexity_level"]

        if complexity <= 3:
            return {
                "phase1": "1å‘¨ï¼šå¿«é€Ÿå¯åŠ¨",
                "phase2": "2-4å‘¨ï¼šæ ¸å¿ƒå®æ–½",
                "phase3": "5-8å‘¨ï¼šå®Œå–„ä¼˜åŒ–",
            }
        elif complexity <= 7:
            return {
                "phase1": "1-2å‘¨ï¼šåŸºç¡€å‡†å¤‡",
                "phase2": "3-8å‘¨ï¼šæ·±å…¥å®æ–½",
                "phase3": "9-16å‘¨ï¼šæŒç»­ä¼˜åŒ–",
            }
        else:
            return {
                "phase1": "2-3å‘¨ï¼šå…¨é¢åˆ†æ",
                "phase2": "4-12å‘¨ï¼šåˆ†æ­¥å®æ–½",
                "phase3": "13-24å‘¨ï¼šé•¿æœŸå·©å›º",
            }

    def _get_stage2_resources(self, context: Dict[str, Any]) -> List[Dict[str, str]]:
        """Get relevant resources for Stage 2."""
        role = context["user_role"]

        resources = [
            {
                "type": "tool",
                "title": "é¡¹ç›®ç®¡ç†å·¥å…·",
                "description": "ç”¨äºè·Ÿè¸ªè¡ŒåŠ¨æ­¥éª¤å’Œè¿›åº¦",
                "url": "https://tools.example.com/project-management",
            },
            {
                "type": "guide",
                "title": "å®æ–½æŒ‡å—",
                "description": f"é’ˆå¯¹{role}çš„è¯¦ç»†å®æ–½æŒ‡å—",
                "url": "https://guides.example.com/implementation",
            },
        ]

        return resources

    def _define_success_metrics(self, context: Dict[str, Any]) -> List[str]:
        """Define success metrics for Stage 2 solutions."""
        return [
            "æŒ‰æ—¶å®Œæˆè®¾å®šçš„è¡ŒåŠ¨æ­¥éª¤",
            "é—®é¢˜è§£å†³è¿›åº¦è¾¾åˆ°é¢„æœŸ",
            "ä¸ªäººèƒ½åŠ›å’Œä¿¡å¿ƒæå‡",
            "å»ºç«‹å¯æŒç»­çš„æ”¹è¿›æœºåˆ¶",
            "è·å¾—é¢„æœŸçš„ç§¯æç»“æœ",
        ]

    async def process_experience_stage3(
        self,
        experience_data: Dict[str, Any],
        stage1_solution: Optional[Dict[str, Any]] = None,
        stage2_solution: Optional[Dict[str, Any]] = None,
        follow_up_data: Dict[str, Any] = None,
        user_role: str = "other",
        additional_context: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """
        Process Stage 3: Follow-up and Experience Supplementation

        Provides ongoing support, progress tracking, and adaptive
        recommendations based on implementation progress.
        """
        start_time = datetime.utcnow()

        try:
            # Get user role template
            role_template = get_template_by_role(UserRole(user_role))

            # Build context for Stage 3 processing
            context = await self._build_stage3_context(
                experience_data,
                stage1_solution,
                stage2_solution,
                follow_up_data or {},
                role_template,
                additional_context or {},
            )

            # Generate Stage 3 follow-up solution
            if self.client:  # Use real AI if available
                solution = await self._generate_stage3_solution(context, role_template)
            else:
                solution = await self._mock_stage3_solution(context, role_template)

            # Calculate processing time
            processing_time = (datetime.utcnow() - start_time).total_seconds()

            # Encrypt sensitive content
            encrypted_content = {
                "title": encrypt_data(solution["title"]),
                "follow_up_plan": encrypt_data(solution["follow_up_plan"]),
                "progress_assessment": encrypt_data(solution["progress_assessment"]),
                "adaptive_recommendations": [
                    encrypt_data(rec) for rec in solution["adaptive_recommendations"]
                ],
                "next_steps": solution["next_steps"],
                "milestone_tracking": solution["milestone_tracking"],
                "support_resources": solution["support_resources"],
                "schedule": solution["schedule"],
            }

            # AI processing metadata
            ai_metadata = {
                "stage": 3,
                "stage_name": "follow_up_support",
                "user_role": context["user_role"],
                "processing_time": processing_time,
                "confidence_score": solution["confidence_score"],
                "model_params": encrypt_object(solution.get("model_params", {})),
                "has_follow_up_data": bool(follow_up_data),
                "stage1_integration": bool(stage1_solution),
                "stage2_integration": bool(stage2_solution),
                "multimodal_analysis": encrypt_object(context["multimodal_insights"]),
                "generated_at": datetime.utcnow().isoformat(),
                "version": "1.0",
            }

            return {
                "content": encrypted_content,
                "ai_metadata": ai_metadata,
                "confidence_score": solution["confidence_score"],
                "stage": 3,
                "success": True,
            }

        except Exception as e:
            print(f"Stage 3 processing error: {e}")
            raise Exception(f"Stage 3 processing failed: {str(e)}")

    async def _build_stage3_context(
        self,
        experience_data: Dict[str, Any],
        stage1_solution: Optional[Dict[str, Any]],
        stage2_solution: Optional[Dict[str, Any]],
        follow_up_data: Dict[str, Any],
        role_template,
        additional_context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Build comprehensive context for Stage 3 processing."""

        # Extract form data
        form_data = self._extract_form_data(experience_data)

        # Analyze multimodal content
        multimodal_analysis = await self._analyze_multimodal_inputs(
            experience_data.get("media_files", [])
        )

        # Extract progress indicators from follow-up data
        progress_indicators = self._extract_progress_indicators(
            follow_up_data, role_template
        )

        # Build context for follow-up processing
        context = {
            "user_role": role_template.role.value,
            "template_name": role_template.name,
            "form_data": form_data,
            "progress_indicators": progress_indicators,
            "multimodal_insights": multimodal_analysis,
            "stage1_foundation": (
                self._extract_stage1_foundation(stage1_solution)
                if stage1_solution
                else None
            ),
            "stage2_implementation": (
                self._extract_stage2_implementation(stage2_solution)
                if stage2_solution
                else None
            ),
            "follow_up_data": follow_up_data,
            "additional_context": additional_context,
            "processing_timestamp": datetime.utcnow().isoformat(),
        }

        return context

    def _extract_progress_indicators(
        self, follow_up_data: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Extract progress indicators from follow-up data."""
        indicators = {
            "progress_rating": follow_up_data.get("progress_rating", 5),
            "satisfaction_level": follow_up_data.get("satisfaction_level", 5),
            "implementation_success": [],
            "ongoing_challenges": [],
            "adaptation_needed": "moderate",
        }

        # Extract specific indicators
        if "implemented_actions" in follow_up_data:
            indicators["implementation_success"] = follow_up_data["implemented_actions"]

        if "challenges_faced" in follow_up_data:
            indicators["ongoing_challenges"] = follow_up_data["challenges_faced"]

        # Determine adaptation level
        progress_rating = indicators["progress_rating"]
        if progress_rating <= 3:
            indicators["adaptation_needed"] = "major"
        elif progress_rating <= 6:
            indicators["adaptation_needed"] = "moderate"
        else:
            indicators["adaptation_needed"] = "minor"

        return indicators

    def _extract_stage2_implementation(
        self, stage2_solution: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Extract implementation status from Stage 2 solution."""
        if not stage2_solution:
            return {}

        content = stage2_solution.get("content", {})

        return {
            "action_steps_defined": bool(content.get("actionSteps")),
            "timeline_established": bool(content.get("implementation_timeline")),
            "resources_provided": bool(content.get("resources")),
            "success_metrics_set": bool(content.get("success_metrics")),
            "confidence_level": stage2_solution.get("metadata", {}).get(
                "confidence_score", 0.7
            ),
        }

    async def _generate_stage3_solution(
        self, context: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Generate Stage 3 follow-up solution using OpenAI."""

        # Build comprehensive prompt for follow-up support
        base_prompt = self._get_default_stage3_prompt(role_template)

        # Fill in context variables
        progress_rating = context["progress_indicators"]["progress_rating"]
        satisfaction = context["progress_indicators"]["satisfaction_level"]
        challenges = ", ".join(context["progress_indicators"]["ongoing_challenges"][:3])
        successes = ", ".join(
            context["progress_indicators"]["implementation_success"][:3]
        )

        prompt_variables = {
            "user_role": context["user_role"],
            "progress_rating": progress_rating,
            "satisfaction_level": satisfaction,
            "challenges": challenges or "æš‚æ— å…·ä½“æŒ‘æˆ˜",
            "successes": successes or "æ­£åœ¨åŠªåŠ›å®æ–½ä¸­",
            "adaptation_level": context["progress_indicators"]["adaptation_needed"],
            "has_stage1": (
                "æœ‰å¿ƒç†ç–—æ„ˆåŸºç¡€" if context["stage1_foundation"] else "ç¼ºå°‘å¿ƒç†åŸºç¡€"
            ),
            "has_stage2": (
                "æœ‰å®æ–½è®¡åˆ’" if context["stage2_implementation"] else "ç¼ºå°‘è¡ŒåŠ¨è®¡åˆ’"
            ),
        }

        # Format the prompt
        try:
            formatted_prompt = base_prompt.format(**prompt_variables)
        except KeyError:
            formatted_prompt = base_prompt

        # Add follow-up specific context
        if context["follow_up_data"]:
            formatted_prompt += "\n\næœ€æ–°åé¦ˆä¿¡æ¯ï¼š"
            if context["follow_up_data"].get("additional_concerns"):
                formatted_prompt += f"\n- é¢å¤–å…³æ³¨ç‚¹: {context['follow_up_data']['additional_concerns']}"

        # Make API call
        response = await self.client.chat.completions.create(
            model=self.model_name,  # ä½¿ç”¨é…ç½®çš„Kimiæ¨¡å‹
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é•¿æœŸæ”¯æŒä¸“å®¶ï¼Œä¸“é—¨æä¾›æŒç»­è·Ÿè¿›ã€è¿›åº¦è¯„ä¼°å’Œé€‚åº”æ€§å»ºè®®ã€‚ä½ çš„å›åº”åº”è¯¥ä½“ç°ä¸ªæ€§åŒ–å…³æ€€ã€å®ç”¨çš„è°ƒæ•´å»ºè®®å’Œé•¿æœŸè§„åˆ’è§†è§’ã€‚",
                },
                {"role": "user", "content": formatted_prompt},
            ],
            temperature=0.7,
            max_tokens=2000,
        )

        content = response.choices[0].message.content

        # Parse and structure the response
        return {
            "title": "é•¿æœŸæ”¯æŒä¸è¿›åº¦è·Ÿè¸ªæ–¹æ¡ˆ",
            "follow_up_plan": content,
            "progress_assessment": self._generate_progress_assessment(context),
            "adaptive_recommendations": self._extract_adaptive_recommendations(content),
            "next_steps": self._generate_next_steps(context),
            "milestone_tracking": self._generate_milestone_tracking(context),
            "support_resources": self._get_stage3_resources(context),
            "schedule": self._generate_follow_up_schedule(context),
            "confidence_score": 0.80,
            "model_params": {
                "model": self.model_name,
                "temperature": 0.7,
                "max_tokens": 2000,
            },
        }

    async def _mock_stage3_solution(
        self, context: Dict[str, Any], role_template
    ) -> Dict[str, Any]:
        """Generate mock Stage 3 solution for testing purposes."""

        role_name = role_template.name
        progress_rating = context["progress_indicators"]["progress_rating"]
        satisfaction = context["progress_indicators"]["satisfaction_level"]

        mock_follow_up_plan = f"""
        äº²çˆ±çš„{role_name}æœ‹å‹ï¼Œ

        åŸºäºæ‚¨çš„è¿›åº¦åé¦ˆï¼ˆè¿›å±•åº¦ï¼š{progress_rating}/10ï¼Œæ»¡æ„åº¦ï¼š{satisfaction}/10ï¼‰ï¼Œæˆ‘ä»¬ä¸ºæ‚¨åˆ¶å®šäº†ä»¥ä¸‹é•¿æœŸæ”¯æŒè®¡åˆ’ï¼š

        ## è¿›å±•è¯„ä¼°
        æ‚¨å½“å‰çš„å®æ–½æƒ…å†µæ•´ä½“{"è‰¯å¥½" if progress_rating >= 7 else "éœ€è¦æ”¹è¿›" if progress_rating >= 4 else "éœ€è¦é‡æ–°è°ƒæ•´"}ã€‚

        ## é€‚åº”æ€§è°ƒæ•´
        æ ¹æ®æ‚¨é‡åˆ°çš„å…·ä½“æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å»ºè®®ä»¥ä¸‹è°ƒæ•´ï¼š
        1. é‡æ–°è¯„ä¼°å½“å‰ç­–ç•¥çš„æœ‰æ•ˆæ€§
        2. æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å®æ–½èŠ‚å¥
        3. åŠ å¼ºåœ¨å›°éš¾é¢†åŸŸçš„æ”¯æŒåŠ›åº¦
        4. å»ºç«‹æ›´çµæ´»çš„åº”å¯¹æœºåˆ¶

        ## æŒç»­æ”¯æŒè®¡åˆ’
        - ä¸¤å‘¨åè¿›è¡Œä¸‹ä¸€æ¬¡è¿›åº¦æ£€æŸ¥
        - æä¾›é’ˆå¯¹æ€§çš„èµ„æºå’Œå·¥å…·
        - å»ºç«‹åŒä¼´æ”¯æŒç½‘ç»œ
        - å®šæœŸä¼˜åŒ–ç­–ç•¥å’Œç›®æ ‡

        è¯·è®°ä½ï¼Œæˆé•¿æ˜¯ä¸€ä¸ªæ¸è¿›çš„è¿‡ç¨‹ï¼Œä¿æŒè€å¿ƒå’ŒåšæŒæ˜¯å…³é”®ã€‚
        """

        return {
            "title": "é•¿æœŸæ”¯æŒä¸è¿›åº¦è·Ÿè¸ªæ–¹æ¡ˆ",
            "follow_up_plan": mock_follow_up_plan.strip(),
            "progress_assessment": self._generate_progress_assessment(context),
            "adaptive_recommendations": [
                "æ ¹æ®å®é™…è¿›å±•è°ƒæ•´æœŸæœ›å’Œç›®æ ‡",
                "åŠ å¼ºåœ¨è–„å¼±ç¯èŠ‚çš„æŠ•å…¥å’Œæ”¯æŒ",
                "å»ºç«‹æ›´é¢‘ç¹çš„è‡ªæˆ‘ç›‘æ§æœºåˆ¶",
                "å¯»æ±‚é¢å¤–çš„ä¸“ä¸šæˆ–åŒä¼´æ”¯æŒ",
            ],
            "next_steps": [
                "æ€»ç»“å½“å‰é˜¶æ®µçš„æˆåŠŸç»éªŒ",
                "è¯†åˆ«å’Œè§£å†³ä¸»è¦éšœç¢",
                "è°ƒæ•´ä¸‹ä¸€é˜¶æ®µçš„è¡ŒåŠ¨è®¡åˆ’",
                "å»ºç«‹æ›´æœ‰æ•ˆçš„æ”¯æŒç³»ç»Ÿ",
            ],
            "milestone_tracking": self._generate_milestone_tracking(context),
            "support_resources": self._get_stage3_resources(context),
            "schedule": self._generate_follow_up_schedule(context),
            "confidence_score": 0.75,
        }

    def _get_default_stage3_prompt(self, role_template) -> str:
        """Get default Stage 3 prompt."""
        return f"""
        ä½œä¸º{role_template.name}ï¼Œç”¨æˆ·åœ¨å®æ–½è§£å†³æ–¹æ¡ˆè¿‡ç¨‹ä¸­çš„è¿›å±•è¯„åˆ†ä¸º{"{progress_rating}"}/10ï¼Œæ»¡æ„åº¦ä¸º{"{satisfaction_level}"}/10ã€‚
        ä¸»è¦æŒ‘æˆ˜åŒ…æ‹¬ï¼š{"{challenges}"}ï¼Œå·²å®ç°çš„æˆåŠŸåŒ…æ‹¬ï¼š{"{successes}"}ã€‚
        éœ€è¦è¿›è¡Œ{"{adaptation_level}"}ç¨‹åº¦çš„ç­–ç•¥è°ƒæ•´ã€‚{"{has_stage1}"}ï¼Œ{"{has_stage2}"}ã€‚

        è¯·æä¾›ï¼š
        1. åŸºäºå½“å‰è¿›å±•çš„å®¢è§‚è¯„ä¼°
        2. é’ˆå¯¹æ€§çš„é€‚åº”è°ƒæ•´å»ºè®®
        3. ä¸‹ä¸€é˜¶æ®µçš„å…·ä½“è¡ŒåŠ¨æ­¥éª¤
        4. é•¿æœŸè·Ÿè¿›å’Œæ”¯æŒè®¡åˆ’
        5. è¿›åº¦é‡Œç¨‹ç¢‘å’Œæ£€æŸ¥æœºåˆ¶
        6. å¿…è¦çš„èµ„æºå’Œå·¥å…·æ¨è

        è¦æ±‚ï¼šæ–¹æ¡ˆè¦ä½“ç°ä¸ªæ€§åŒ–å…³æ€€ï¼Œæä¾›å®ç”¨çš„è°ƒæ•´ç­–ç•¥ï¼Œå»ºç«‹å¯æŒç»­çš„æ”¯æŒæœºåˆ¶ã€‚
        """

    def _generate_progress_assessment(self, context: Dict[str, Any]) -> str:
        """Generate progress assessment based on context."""
        progress_rating = context["progress_indicators"]["progress_rating"]
        satisfaction = context["progress_indicators"]["satisfaction_level"]

        if progress_rating >= 8 and satisfaction >= 7:
            return "æ‚¨çš„è¿›å±•éå¸¸å¥½ï¼å®æ–½æ•ˆæœè¶…å‡ºé¢„æœŸï¼Œå»ºè®®ç»§ç»­å½“å‰ç­–ç•¥å¹¶é€æ­¥æ‰©å±•ã€‚"
        elif progress_rating >= 6 and satisfaction >= 5:
            return "æ‚¨çš„è¿›å±•ç¨³å®šï¼Œæœ‰ä¸€å®šæˆæ•ˆã€‚å»ºè®®åœ¨ç°æœ‰åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒä¼˜åŒ–ã€‚"
        elif progress_rating >= 4:
            return "æ‚¨çš„è¿›å±•é‡åˆ°ä¸€äº›æŒ‘æˆ˜ï¼Œéœ€è¦é‡æ–°è¯„ä¼°å’Œè°ƒæ•´ç­–ç•¥ï¼Œä½†åŸºç¡€ä¾ç„¶è‰¯å¥½ã€‚"
        else:
            return "å½“å‰ç­–ç•¥éœ€è¦é‡å¤§è°ƒæ•´ã€‚å»ºè®®æš‚åœå½“å‰æ–¹æ³•ï¼Œé‡æ–°åˆ¶å®šæ›´é€‚åˆçš„æ–¹æ¡ˆã€‚"

    def _extract_adaptive_recommendations(self, content: str) -> List[str]:
        """Extract adaptive recommendations from AI response."""
        recommendations = []
        lines = content.split("\n")
        for line in lines:
            if any(
                keyword in line.lower() for keyword in ["å»ºè®®", "è°ƒæ•´", "æ”¹è¿›", "ä¼˜åŒ–"]
            ):
                if len(line.strip()) > 15:
                    recommendations.append(line.strip())

        if not recommendations:
            recommendations = [
                "æ ¹æ®å½“å‰è¿›å±•è°ƒæ•´æœŸæœ›ç›®æ ‡",
                "åŠ å¼ºè–„å¼±ç¯èŠ‚çš„æ”¯æŒåŠ›åº¦",
                "å»ºç«‹æ›´æœ‰æ•ˆçš„ç›‘æ§æœºåˆ¶",
                "å¯»æ±‚é€‚å½“çš„å¤–éƒ¨æ”¯æŒ",
            ]

        return recommendations[:6]

    def _generate_next_steps(self, context: Dict[str, Any]) -> List[str]:
        """Generate next steps based on progress."""
        progress_rating = context["progress_indicators"]["progress_rating"]

        if progress_rating >= 7:
            return [
                "å·©å›ºå½“å‰çš„æˆåŠŸåšæ³•",
                "é€æ­¥æ‰©å±•åˆ°ç›¸å…³é¢†åŸŸ",
                "å»ºç«‹é•¿æœŸç»´æŒæœºåˆ¶",
                "åˆ†äº«ç»éªŒå¸®åŠ©ä»–äºº",
            ]
        elif progress_rating >= 4:
            return [
                "åˆ†æå½“å‰æŒ‘æˆ˜çš„æ ¹æœ¬åŸå› ",
                "è°ƒæ•´å®æ–½ç­–ç•¥å’ŒèŠ‚å¥",
                "å¯»æ±‚é¢å¤–çš„æ”¯æŒèµ„æº",
                "è®¾å®šæ›´ç°å®çš„çŸ­æœŸç›®æ ‡",
            ]
        else:
            return [
                "æš‚åœå½“å‰æ–¹æ³•å¹¶é‡æ–°è¯„ä¼°",
                "å¯»æ±‚ä¸“ä¸šæŒ‡å¯¼å’Œæ”¯æŒ",
                "é‡æ–°åˆ¶å®šåŸºç¡€è¡ŒåŠ¨è®¡åˆ’",
                "å»ºç«‹æ›´å¼ºçš„æ”¯æŒç³»ç»Ÿ",
            ]

    def _generate_milestone_tracking(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate milestone tracking system."""
        return {
            "weekly_check": "æ¯å‘¨è‡ªæˆ‘è¯„ä¼°è¿›å±•å’ŒæŒ‘æˆ˜",
            "bi_weekly_review": "ä¸¤å‘¨ä¸€æ¬¡æ·±åº¦å›é¡¾å’Œè°ƒæ•´",
            "monthly_assessment": "æœˆåº¦å…¨é¢è¯„ä¼°å’Œè§„åˆ’",
            "quarterly_planning": "å­£åº¦æˆ˜ç•¥å›é¡¾å’Œé•¿æœŸè§„åˆ’",
        }

    def _get_stage3_resources(self, context: Dict[str, Any]) -> List[Dict[str, str]]:
        """Get relevant resources for Stage 3."""
        role = context["user_role"]

        resources = [
            {
                "type": "tracking",
                "title": "è¿›åº¦è¿½è¸ªå·¥å…·",
                "description": "ç”¨äºè®°å½•å’Œç›‘æ§å®æ–½è¿›å±•",
                "url": "https://tools.example.com/progress-tracking",
            },
            {
                "type": "community",
                "title": "æ”¯æŒç¤¾ç¾¤",
                "description": f"ä¸å…¶ä»–{role}åˆ†äº«ç»éªŒå’Œç›¸äº’æ”¯æŒ",
                "url": "https://community.example.com/support",
            },
            {
                "type": "resource",
                "title": "æŒç»­å­¦ä¹ èµ„æº",
                "description": "ç›¸å…³æŠ€èƒ½æå‡å’ŒçŸ¥è¯†è¡¥å……",
                "url": "https://resources.example.com/learning",
            },
        ]

        return resources

    def _generate_follow_up_schedule(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate follow-up schedule."""
        progress_rating = context["progress_indicators"]["progress_rating"]

        if progress_rating <= 4:
            return {
                "next_check": "1å‘¨å",
                "frequency": "æ¯å‘¨æ£€æŸ¥",
                "duration": "è‡³å°‘1ä¸ªæœˆ",
                "adjustment_period": "2å‘¨",
            }
        elif progress_rating <= 7:
            return {
                "next_check": "2å‘¨å",
                "frequency": "åŒå‘¨æ£€æŸ¥",
                "duration": "2-3ä¸ªæœˆ",
                "adjustment_period": "1ä¸ªæœˆ",
            }
        else:
            return {
                "next_check": "1ä¸ªæœˆå",
                "frequency": "æœˆåº¦æ£€æŸ¥",
                "duration": "3-6ä¸ªæœˆ",
                "adjustment_period": "å­£åº¦è°ƒæ•´",
            }

    async def process_follow_up_adaptation(
        self,
        current_solution: Dict[str, Any],
        follow_up_data: Dict[str, Any],
        user_role: str,
    ) -> Dict[str, Any]:
        """Process follow-up data to generate adaptive recommendations."""

        try:
            # Analyze follow-up data
            progress_rating = follow_up_data.get("progress_rating", 5)
            satisfaction = follow_up_data.get("satisfaction_level", 5)
            challenges = follow_up_data.get("challenges_faced", [])
            successes = follow_up_data.get("success_stories", [])

            # Generate adaptive recommendations
            if progress_rating <= 3:
                recommendations = [
                    "é‡æ–°è¯„ä¼°å½“å‰æ–¹æ³•çš„é€‚ç”¨æ€§",
                    "å¯»æ±‚æ›´å¤šä¸“ä¸šæ”¯æŒå’ŒæŒ‡å¯¼",
                    "é™ä½ç›®æ ‡éš¾åº¦ï¼Œå»ºç«‹å°æ­¥æˆåŠŸ",
                    "åŠ å¼ºåŸºç¡€æŠ€èƒ½å’Œå¿ƒç†å‡†å¤‡",
                ]
                assessment = "å½“å‰è¿›å±•é‡åˆ°é‡å¤§æŒ‘æˆ˜ï¼Œéœ€è¦å…¨é¢é‡æ–°è§„åˆ’æ–¹æ³•ã€‚"
            elif progress_rating <= 6:
                recommendations = [
                    "è¯†åˆ«å’Œè§£å†³ä¸»è¦éšœç¢å› ç´ ",
                    "è°ƒæ•´å®æ–½èŠ‚å¥å’ŒæœŸæœ›ç›®æ ‡",
                    "åŠ å¼ºåœ¨å›°éš¾é¢†åŸŸçš„ç»ƒä¹ ",
                    "å¯»æ±‚åŒä¼´æ”¯æŒå’Œç»éªŒåˆ†äº«",
                ]
                assessment = "è¿›å±•ç¨³å®šä½†ä»æœ‰æ”¹è¿›ç©ºé—´ï¼Œå»ºè®®é€‚åº¦è°ƒæ•´ç­–ç•¥ã€‚"
            else:
                recommendations = [
                    "ç»§ç»­å¹¶æ‰©å±•å½“å‰æˆåŠŸåšæ³•",
                    "æŒ‘æˆ˜æ›´é«˜å±‚æ¬¡çš„ç›®æ ‡",
                    "åˆ†äº«ç»éªŒå¸®åŠ©ä»–äººæˆé•¿",
                    "å»ºç«‹é•¿æœŸç»´æŒå’Œæ”¹è¿›æœºåˆ¶",
                ]
                assessment = "è¿›å±•è‰¯å¥½ï¼Œå¯ä»¥åœ¨ç°æœ‰åŸºç¡€ä¸Šè¿›ä¸€æ­¥æå‡ã€‚"

            return {
                "adaptive_recommendations": recommendations,
                "progress_assessment": assessment,
                "confidence_score": max(0.6, min(0.9, progress_rating / 10)),
            }

        except Exception as e:
            print(f"Follow-up adaptation error: {e}")
            return {
                "adaptive_recommendations": ["ç»§ç»­å½“å‰æ–¹æ³•å¹¶ä¿æŒè€å¿ƒ"],
                "progress_assessment": "éœ€è¦æ›´å¤šæ—¶é—´è§‚å¯Ÿè¿›å±•æƒ…å†µ",
                "confidence_score": 0.7,
            }


# Create singleton instance
enhanced_ai_service = EnhancedAIService()
